# Task W4.T02 Output Notes

**Task:** Implement Script Itemizer
**Completed:** 2025-11-23
**Time Taken:** ~5 hours
**Status:** Complete

---

## Implementation Summary

Implemented a comprehensive script itemizer for the text shaping pipeline. The script itemizer analyzes text and splits it into contiguous runs where each run contains characters of the same Unicode script (Latin, Arabic, Hebrew, Han, Devanagari, etc.).

The implementation consists of:

1. **`ScriptRun` struct** - Represents a run of text with uniform script, storing byte offsets and the Unicode script
2. **`itemize_scripts` function** - Main itemization algorithm that processes text and produces script runs
3. **Emoji detection helpers** - Functions to identify emoji, ZWJ, variation selectors, and skin tone modifiers

The algorithm handles Common and Inherited scripts intelligently - when Common characters (like punctuation, digits, whitespace) appear between explicit script runs, they are assigned to the PRECEDING script run. This matches CSS text rendering expectations where "Hello, " stays together as Latin rather than splitting at the comma.

---

## API Contracts

### Main Types

```rust
/// A run of text with a uniform Unicode script.
#[derive(Debug, Clone, PartialEq, Eq)]
pub struct ScriptRun {
    /// Byte offset of the start of this run in the original text.
    pub start: usize,

    /// Byte offset of the end of this run (exclusive) in the original text.
    pub end: usize,

    /// The Unicode script for this run.
    pub script: unicode_script::Script,
}

impl ScriptRun {
    pub fn new(start: usize, end: usize, script: Script) -> Self;
    pub fn len(&self) -> usize;
    pub fn is_empty(&self) -> bool;
    pub fn text_slice<'a>(&self, text: &'a str) -> &'a str;
}
```

### Main Functions

```rust
/// Itemizes text into runs of the same Unicode script.
pub fn itemize_scripts(text: &str) -> Vec<ScriptRun>;

/// Emoji detection helpers
pub fn is_emoji(ch: char) -> bool;
pub fn is_zwj(ch: char) -> bool;
pub fn is_variation_selector(ch: char) -> bool;
pub fn is_skin_tone_modifier(ch: char) -> bool;
```

### Module Exports

All types are exported from `fastrender::text`:
```rust
pub use script::{
    itemize_scripts, ScriptRun,
    is_emoji, is_zwj, is_variation_selector, is_skin_tone_modifier
};
```

---

## Decisions Made

### Decision 1: Common Characters Go to Preceding Run

**Context:** When Common characters (punctuation, digits, whitespace) appear between two different explicit scripts, they could be assigned to either the preceding or following run.

**Decision:** Common characters are assigned to the PRECEDING script run.

**Rationale:**
- More intuitive for text like "Hello, " - the comma and space stay with "Hello"
- Matches typical CSS text rendering behavior
- Avoids orphaned punctuation at the start of RTL runs

**Impact:**
- "Hello שלום" produces: ["Hello " (Latin), "שלום" (Hebrew)]
- Not: ["Hello" (Latin), " שלום" (Hebrew)]

### Decision 2: Default Script for All-Common Text

**Context:** Text consisting entirely of Common characters (digits, punctuation, symbols) has no explicit script.

**Decision:** Default to `Script::Latin` for all-Common text.

**Rationale:**
- Latin is the most common default in web rendering
- Matches Unicode's neutral script concept
- Consistent with CSS font fallback expectations

**Impact:**
- "123 456" produces: [entire text as Latin]
- "...!!!" produces: [entire text as Latin]

### Decision 3: Byte Offsets (Not Character Indices)

**Context:** ScriptRun could store either byte offsets or character indices.

**Decision:** Store byte offsets into the UTF-8 string.

**Rationale:**
- Consistent with Rust's `&str[start..end]` slicing
- Compatible with HarfBuzz/rustybuzz cluster indices
- Efficient for text processing pipelines

**Impact:**
- "Aя字" (1+2+3 = 6 bytes) produces runs with offsets [0,1], [1,3], [3,6]
- Use `text[run.start..run.end]` to extract text
- Use `run.text_slice(text)` helper for convenience

### Decision 4: No Script Merging for CJK

**Context:** Japanese text often mixes Han, Hiragana, and Katakana scripts. Some systems merge these into a single "CJK" category.

**Decision:** Keep Han, Hiragana, and Katakana as separate scripts.

**Rationale:**
- Follows Unicode UAX #24 specification
- Different scripts may need different fonts
- Font fallback system handles font selection per-run

**Impact:**
- "漢字ひらがなカタカナ" produces 3 separate runs
- Downstream tasks (font itemizer) can merge if needed

---

## Spec Interpretations

### UAX #24: Script Property

**Spec says:** Every Unicode character has a script property from UAX #24.

**Interpretation:**
- Used `unicode-script` crate which implements UAX #24
- Common script includes punctuation, digits, whitespace
- Inherited script includes combining marks

### Common/Inherited Resolution

**Spec says:** Common and Inherited characters should be resolved to surrounding scripts.

**Interpretation:**
- Track pending Common/Inherited characters during iteration
- When explicit script changes, assign pending chars to PREVIOUS run
- When same explicit script continues, clear pending (absorbed into current run)
- Trailing Common/Inherited chars go to final run

---

## Discoveries & Gotchas

### Discovery 1: Unicode Space Characters

**Finding:** Not all whitespace is equal in Unicode. Some whitespace characters have explicit scripts.

**Examples:**
- U+0020 SPACE - Common (handled)
- U+00A0 NBSP - Common (handled)
- U+3000 Ideographic Space - Common (handled)

**Implication:** Our Common character handling works correctly for all whitespace.

### Discovery 2: Emoji Complexity

**Finding:** Emoji detection is complex due to:
- ZWJ sequences (family emoji)
- Skin tone modifiers
- Variation selectors (text vs emoji presentation)
- Regional indicator pairs (flags)

**Implication:** Provided `is_emoji`, `is_zwj`, `is_variation_selector`, `is_skin_tone_modifier` helpers for downstream use.

### Discovery 3: Script Changes Per-Character

**Finding:** Some text can have rapid script changes character-by-character.

**Example:** "AяBбCвDг" alternates Latin/Cyrillic every character.

**Implication:** Algorithm handles this correctly, producing 8 separate runs. Performance is O(n) regardless of number of script changes.

---

## Performance Notes

### Algorithmic Complexity

- **Time:** O(n) where n = text length in bytes
- **Space:** O(k) where k = number of runs (typically << n)
- **Operations:** Single pass through text, no backtracking

### Memory Allocation

- One `Vec<ScriptRun>` allocation per call
- No intermediate string allocations
- ScriptRun is small (24 bytes: 3 usizes)

### Benchmarking Targets

For typical text processing:
- 10KB text: < 1ms
- 100KB text: < 10ms
- 1MB text: < 100ms

### Optimization Opportunities

If needed:
- Pre-size Vec based on text length heuristic
- SIMD for script lookup (complex due to Unicode tables)
- Cache script runs for repeated layout passes

---

## Recommendations for Downstream Tasks

### For W4.T03 (Bidi Analyzer)

**Integration Pattern:**
```rust
// Run bidi analysis first, then script itemization
let bidi_info = bidi_analyzer.analyze(text, direction)?;

// Script itemizer can use bidi levels for more precise runs
let script_runs = itemize_scripts(text);

// Combine for font itemization
for run in script_runs {
    let direction = bidi_info.direction_at(run.start);
    // Use direction + script for font selection
}
```

**Key Points:**
- Bidi and script are orthogonal concerns
- A script run can span multiple bidi levels
- A bidi level can span multiple script runs
- Consider combining both for text shaping runs

### For W4.T04 (Font Itemizer)

**Use Script Runs for Font Selection:**
```rust
use fastrender::text::script::{itemize_scripts, ScriptRun};

let script_runs = itemize_scripts(text);
for run in script_runs {
    // Select font that supports this script
    let font = font_loader.select_for_script(run.script, style);

    // If no single font covers the run, split further
    let font_runs = font_itemizer.itemize(run.text_slice(text), font_list);
}
```

**Key Points:**
- Not all fonts support all scripts
- Script runs are a coarse split - may need further splitting for font coverage
- Han (Chinese) script is large - may need multiple fonts for full coverage

### For W4.T05 (Text Shaper)

**Shape Each Script Run Separately:**
```rust
let script_runs = itemize_scripts(text);
let mut shaped_runs = Vec::new();

for run in script_runs {
    let font = get_font_for_script(run.script);
    let shaped = shaper.shape(
        run.text_slice(text),
        font,
        run.script,  // Pass script to shaper for HarfBuzz
    );
    shaped_runs.push(shaped);
}
```

**Key Points:**
- HarfBuzz needs script hint for proper shaping
- Convert `unicode_script::Script` to `rustybuzz::Script`
- Maintain byte offset mapping through shaping

### For W4.T12 (Inline Layout)

**Script Runs Map to InlineBox Segments:**
```rust
// During inline layout
let script_runs = itemize_scripts(text_content);

for run in script_runs {
    let shaped = shaper.shape(run.text_slice(text_content), ...);

    // Create inline box for this run
    let inline_box = InlineBox::new(
        shaped.glyphs,
        run.start..run.end,  // Original text range
        run.script,
    );

    inline_boxes.push(inline_box);
}
```

**Key Points:**
- Preserve byte offset mapping for hit testing
- Script boundaries may not align with line breaks
- Handle script changes within words carefully

---

## Open Questions

### Question 1: Should we merge Japanese scripts?

**Context:** Japanese text mixes Han, Hiragana, and Katakana frequently.

**Options:**
1. Keep separate (current implementation)
2. Merge all CJK scripts when consecutive
3. Let font itemizer handle merging

**Recommendation:** Keep separate. Font itemizer is the right place to decide merging based on font capabilities.

**Resolution:** Leave for W4.T04 (Font Itemizer) to decide.

### Question 2: How to handle grapheme clusters?

**Context:** Some Unicode sequences should stay together (emoji, combining marks).

**Options:**
1. Split at grapheme cluster boundaries
2. Split at codepoint boundaries (current)
3. Hybrid approach

**Recommendation:** Current codepoint-based approach is sufficient. Grapheme clustering is handled by HarfBuzz during shaping.

**Resolution:** No change needed - shaper handles this.

### Question 3: Performance optimization with SIMD?

**Context:** Script lookup is table-based, could potentially be vectorized.

**Options:**
1. Use current `unicode-script` crate (current)
2. Custom SIMD implementation
3. Cached lookup tables

**Recommendation:** Profile first. Current implementation is likely fast enough.

**Resolution:** Defer until profiling shows need.

---

## Test Coverage

### Unit Tests (40 tests)

**Single Script Tests:**
- [x] Empty text
- [x] Latin
- [x] Cyrillic
- [x] Greek
- [x] Hebrew
- [x] Arabic
- [x] Han (Chinese)
- [x] Hiragana
- [x] Katakana
- [x] Hangul (Korean)
- [x] Devanagari
- [x] Thai

**Mixed Script Tests:**
- [x] Latin + Hebrew
- [x] Latin + Arabic
- [x] Latin + Cyrillic
- [x] Multiple scripts in sequence

**Common/Inherited Tests:**
- [x] Punctuation with Latin
- [x] Digits within text
- [x] Digits between scripts
- [x] Only Common characters
- [x] Only punctuation
- [x] Whitespace only

**Emoji Tests:**
- [x] Simple emoji
- [x] Emoji only text
- [x] Emoji detection function
- [x] ZWJ detection
- [x] Variation selector detection
- [x] Skin tone modifier detection

**Edge Cases:**
- [x] Single character (ASCII)
- [x] Single character (multibyte)
- [x] Byte offset verification

### Integration Tests (59 tests)

- [x] All single scripts (12 tests)
- [x] Mixed scripts (5 tests)
- [x] Common character handling (6 tests)
- [x] Emoji handling (8 tests)
- [x] Edge cases (4 tests)
- [x] Byte offset tests (4 tests)
- [x] ScriptRun API tests (6 tests)
- [x] Real-world text tests (6 tests)
- [x] Japanese mixed writing (3 tests)
- [x] Stress tests (3 tests)

### Test Gaps

- Thai dictionary-based segmentation (out of scope)
- Very large texts (>1MB) - should add benchmarks
- Malformed UTF-8 (handled by Rust's str guarantees)

---

## Files Created

| File | Lines | Description |
|------|-------|-------------|
| `src/text/script.rs` | ~700 | Script itemizer implementation |
| `tests/text_script_test.rs` | ~500 | Integration tests |
| `outputs/notes/W4.T02-notes.md` | ~400 | This notes file |

---

## Verification Results

```
Task: W4.T02 - Implement Script Itemizer
Status: COMPLETE

Verification:
 cargo build - SUCCESS
 cargo test text::script - 40/40 tests passed
 cargo test --test text_script_test - 59/59 tests passed
 cargo clippy -- -D warnings - no warnings (fastrender crate)
 cargo fmt --check - formatted correctly

Files Created:
 src/text/script.rs
 tests/text_script_test.rs
 outputs/notes/W4.T02-notes.md

Dependencies Added:
 unicode-script = "0.5" (Cargo.toml)
```

---

**Notes Completed:** 2025-11-23
**Author:** Claude (Automated Agent)
